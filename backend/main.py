import traceback
import io
import json
from fastapi import FastAPI, UploadFile, File, HTTPException, Form, Request
from typing import Dict, Any, Optional
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from sqlalchemy import create_engine, Column, String, Integer, LargeBinary, Text
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker

# ì„œë¹„ìŠ¤ ë¡œì§ ì„í¬íŠ¸
from services.ai_service import get_ai_insight
from services.file_handler import preprocess_file
from services.cdc_logic import run_cdc_analysis

# ==========================================
# [DB ì„¤ì •] SQLite
# ==========================================
# SQLALCHEMY_DATABASE_URL = "sqlite:///./cdc_dashboard.db" # local ìš©
SQLALCHEMY_DATABASE_URL = "sqlite:////app/data/cdc_database.db"

engine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={"check_same_thread": False})
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

class DailyData(Base):
    __tablename__ = "daily_data"
    date = Column(String, primary_key=True, index=True) 
    filename = Column(String)
    content = Column(LargeBinary) 

class ReportCache(Base):
    __tablename__ = "report_cache"
    id = Column(String, primary_key=True, index=True) 
    date_old = Column(String)
    date_new = Column(String)
    result_json = Column(Text) 

Base.metadata.create_all(bind=engine)

# ==========================================
# [FastAPI ì„¤ì •]
# ==========================================
app = FastAPI(title="Project CDC Backend")

origins = [
    "http://localhost:5173",
    "http://localhost:5174",
    "*"  # ê°œë°œ ì¤‘ì—ëŠ” ëª¨ë‘ í—ˆìš©
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class AnalyzeRequest(BaseModel):
    date_old: str
    date_new: str

# ---------------------------------------------------------
# API: íŒŒì¼ ì—…ë¡œë“œ
# ---------------------------------------------------------
@app.post("/api/upload")
async def upload_daily_file(
    date: str = Form(...),
    file: UploadFile = File(...)
):
    db = SessionLocal()
    try:
        content = await file.read()
        existing = db.query(DailyData).filter(DailyData.date == date).first()
        
        if existing:
            existing.filename = file.filename
            existing.content = content
        else:
            new_data = DailyData(date=date, filename=file.filename, content=content)
            db.add(new_data)
        
        db.query(ReportCache).filter(
            (ReportCache.date_old == date) | (ReportCache.date_new == date)
        ).delete()
        
        db.commit()
        return {"message": "ì €ì¥ ì™„ë£Œ"}
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        db.close()

# ---------------------------------------------------------
# API: ë‚ ì§œ ëª©ë¡ ì¡°íšŒ
# ---------------------------------------------------------
@app.get("/api/dates")
def get_uploaded_dates():
    db = SessionLocal()
    dates = db.query(DailyData.date).all()
    db.close()
    return [d[0] for d in dates]

# ---------------------------------------------------------
# API: ë°ì´í„° ì‚­ì œ
# ---------------------------------------------------------
@app.delete("/api/delete/{date}")
def delete_daily_data(date: str):
    db = SessionLocal()
    try:
        record = db.query(DailyData).filter(DailyData.date == date).first()
        if not record:
            raise HTTPException(status_code=404, detail="ë°ì´í„° ì—†ìŒ")
        
        db.delete(record)
        db.query(ReportCache).filter((ReportCache.date_old == date) | (ReportCache.date_new == date)).delete()
        
        db.commit()
        return {"message": "ì‚­ì œ ì™„ë£Œ"}
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        db.close()

# ---------------------------------------------------------
# API: ë¶„ì„ (DB ê¸°ë°˜)
# ---------------------------------------------------------
@app.post("/api/analyze")
def analyze_dates(req: AnalyzeRequest):
    db = SessionLocal()
    try:
        cache_key = f"{req.date_old}_{req.date_new}"
        
        data_old = db.query(DailyData).filter(DailyData.date == req.date_old).first()
        data_new = db.query(DailyData).filter(DailyData.date == req.date_new).first()

        if not data_old or not data_new:
            raise HTTPException(status_code=404, detail="ì›ë³¸ íŒŒì¼ ì—†ìŒ")

        df_old = preprocess_file(data_old.content)
        df_new = preprocess_file(data_new.content)

        if df_old is None or df_new is None:
            raise HTTPException(status_code=400, detail="ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤íŒ¨")

        result = run_cdc_analysis(df_old, df_new, req.date_new)
        
        db.query(ReportCache).filter(ReportCache.id == cache_key).delete()
        new_cache = ReportCache(id=cache_key, date_old=req.date_old, date_new=req.date_new, result_json=json.dumps(result, ensure_ascii=False))
        db.add(new_cache)
        db.commit()

        return {"message": "ë¶„ì„ ì™„ë£Œ", "data": result}
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        db.close()

# # ---------------------------------------------------------
# # API: AI ì§ˆë¬¸ (Pydantic ìš°íšŒ - ë””ë²„ê¹…ìš©)
# # ---------------------------------------------------------
# @app.post("/api/ask-report")
# async def ask_report(request: Request):
#     """
#     [ê°•ë ¥ ë””ë²„ê¹… ëª¨ë“œ] 
#     ì–´ë–¤ ë°ì´í„° í˜•ì‹ì´ ì˜¤ë“  ì—ëŸ¬ë¥¼ ë‚´ì§€ ì•Šê³  ë°›ì•„ì„œ í™•ì¸í•©ë‹ˆë‹¤.
#     """
#     try:
#         # 1. ì›ë³¸ ë°ì´í„° ìˆ˜ì‹ 
#         body = await request.json()
#         print(f"ğŸ”¥ [DEBUG] ìˆ˜ì‹ ëœ ë°ì´í„° í‚¤: {list(body.keys())}")
        
#         # 2. ë°ì´í„° ì¶”ì¶œ (ì•ˆì „í•˜ê²Œ get ì‚¬ìš©)
#         question = body.get("question", "")
#         context_data = body.get("context_data", {})
        
#         print(f"âœ… ì§ˆë¬¸: {question}")
#         print(f"âœ… ë°ì´í„° íƒ€ì…: {type(context_data)}")
        
#         # 3. ë°ì´í„°ê°€ í˜¹ì‹œ ë¬¸ìì—´ë¡œ ì™”ë‹¤ë©´ íŒŒì‹± ì‹œë„ (ë°©ì–´ ë¡œì§)
#         if isinstance(context_data, str):
#             print("âš ï¸ ë°ì´í„°ê°€ ë¬¸ìì—´ë¡œ ì˜´ -> JSON íŒŒì‹± ì‹œë„")
#             try:
#                 context_data = json.loads(context_data)
#             except:
#                 print("âŒ JSON íŒŒì‹± ì‹¤íŒ¨")
        
#         # 4. ì„œë¹„ìŠ¤ í˜¸ì¶œ
#         answer = get_ai_insight(question, context_data)
#         return {"answer": answer}
        
#     except Exception as e:
#         traceback.print_exc()
#         # 422 ëŒ€ì‹  500 ì—ëŸ¬ì™€ í•¨ê»˜ ìƒì„¸ ë‚´ìš©ì„ ë°˜í™˜í•˜ì—¬ ë””ë²„ê¹…
#         return {"answer": f"ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}

class ReportRequest(BaseModel):
    question: str
    context_data: Any
@app.post("/api/ask-report")
async def ask_report(req: ReportRequest):
    """
    Pydantic ëª¨ë¸(ReportRequest)ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ê²€ì¦í•˜ê³  ë°›ìŠµë‹ˆë‹¤.
    """
    # ë””ë²„ê¹…: ì‹¤ì œë¡œ ë“¤ì–´ì˜¨ ë°ì´í„° íƒ€ì… ì°ì–´ë³´ê¸°
    print(f"ğŸ“¥ [ì§ˆë¬¸]: {req.question}")
    print(f"ğŸ“¥ [ë°ì´í„° íƒ€ì…]: {type(req.context_data)}")
    
    # ë°ì´í„° ì •ì œ (ë§Œì•½ ë¬¸ìì—´ë¡œ ì™”ì„ ê²½ìš° ëŒ€ë¹„)
    data = req.context_data
    if isinstance(data, str):
        try:
            data = json.loads(data)
        except:
            pass

    answer = get_ai_insight(req.question, data)
    return {"answer": answer}

@app.get("/api/stats/monthly")
def get_monthly_stats(year: str, month: str):
    """
    [ìµœì í™” ë²„ì „]
    ì´ë¯¸ ë¶„ì„ë˜ì–´ DB(ReportCache)ì— ì €ì¥ëœ 'total_impact' ê°’ë§Œ ë¹ ë¥´ê²Œ ì¡°íšŒí•©ë‹ˆë‹¤.
    ë¶„ì„í•˜ì§€ ì•Šì€ ë‚ ì§œëŠ” 0ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    db = SessionLocal()
    try:
        # 1. ì „ì²´ ë‚ ì§œ ëª©ë¡ ë¡œë“œ (ìˆœì„œ íŒŒì•…ìš©)
        # (Tip: ë°ì´í„°ê°€ ìˆ˜ë§Œ ê±´ì´ ì•„ë‹ˆë¯€ë¡œ ì „ì²´ ë‚ ì§œ ë¡œë“œëŠ” ë§¤ìš° ë¹ ë¦„)
        all_dates = db.query(DailyData.date).order_by(DailyData.date).all()
        all_dates = [d[0] for d in all_dates]

        # 2. ìš”ì²­í•œ 'ë…„-ì›”'ì— í•´ë‹¹í•˜ëŠ” ë‚ ì§œë§Œ í•„í„°ë§
        target_prefix = f"{year}-{month.zfill(2)}"
        target_dates = [d for d in all_dates if d.startswith(target_prefix)]

        stats = []

        for curr_date in target_dates:
            try:
                # 3. ì „ì¼ ë‚ ì§œ ì°¾ê¸° (Cache Key ìƒì„±ìš©)
                curr_idx = all_dates.index(curr_date)
                
                # ì²« ë²ˆì§¸ ë°ì´í„°ë¼ ë¹„êµ ëŒ€ìƒì´ ì—†ìœ¼ë©´ 0
                if curr_idx == 0:
                    stats.append({"date": curr_date, "impact": 0})
                    continue
                
                prev_date = all_dates[curr_idx - 1]
                cache_key = f"{prev_date}_{curr_date}"

                # 4. ğŸ”¥ [í•µì‹¬] ReportCache í…Œì´ë¸”ë§Œ ì¡°íšŒ (ë¶„ì„ ë¡œì§ ì‹¤í–‰ X)
                cached = db.query(ReportCache).filter(ReportCache.id == cache_key).first()
                
                if cached:
                    # DBì— ì €ì¥ëœ JSON íŒŒì‹± -> total_impact ì¶”ì¶œ
                    import json
                    result_json = json.loads(cached.result_json)
                    impact = result_json.get("summary_stats", {}).get("total_impact", 0)
                    stats.append({"date": curr_date, "impact": impact})
                else:
                    # íŒŒì¼ì€ ìˆëŠ”ë° ì•„ì§ 'ë¶„ì„' ë²„íŠ¼ì„ ì•ˆ ëˆ„ë¥¸ ê²½ìš° -> 0 ì²˜ë¦¬
                    stats.append({"date": curr_date, "impact": 0})
            
            except Exception as e:
                print(f"Stats Error ({curr_date}): {e}")
                stats.append({"date": curr_date, "impact": 0})

        return stats

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        db.close()
        
if __name__ == "__main__":
    import uvicorn
    # ì™¸ë¶€ ì ‘ì† í—ˆìš© (host 0.0.0.0)
    uvicorn.run(app, host="0.0.0.0", port=7676)